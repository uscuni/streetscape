{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce44911",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>URBASPACE - SIGHT LINES</h1>\n",
    "    <h2>Indicators</h2>\n",
    "    <h3 style = 'color:#FF5733'>Compute street indicators (from sightlines)</h3>        \n",
    "</center>\n",
    "<hr/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93d8dd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a042e2",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b77a5060",
   "metadata": {},
   "source": [
    "PARAM_insee_layer_name = 'departments'\n",
    "PARAM_insee_codes=['31', '33', '75', '77', '78', '91', '92', '93', '94','95']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f00852",
   "metadata": {},
   "source": [
    "# Configuration choisie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf91a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAM_insee_layer_name,PARAM_insee_codes = 'samples', ['place_de_gaulle']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cb00f4",
   "metadata": {},
   "source": [
    "# Param√®tres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1fb22e6",
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "PARAM_default_street_width = 3\n",
    "\n",
    "PARAM_tan_line_width=300\n",
    "PARAM_sight_line_width=50\n",
    "PARAM_sight_line_spacing=3\n",
    "PARAM_sight_line_junction_size = 0.5\n",
    "PARAM_sight_line_angle_tolerance = 5\n",
    "\n",
    "PARAM_building_categories_count = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "675c1915",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sightlines = pd.read_pickle('my_results/method_1/06_alpes_maritimes_clip.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14969120",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39c71035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.5 contribution if parralel with previous sightpoint setback\n",
    "# 0.5 contribution if parralel with next sightpoint setback\n",
    "\n",
    "def compute_parallelism_factor(side_SB,\n",
    "                               side_SB_count,\n",
    "                               max_distance=999):\n",
    "\n",
    "    if side_SB_count is None or len(side_SB_count)==0:\n",
    "        return []\n",
    "    is_parralel_with_next = []\n",
    "    for sb_a,sb_a_count,sb_b,sb_b_count in zip(side_SB[0:-1],\n",
    "                                               side_SB_count[0:-1],\n",
    "                                               side_SB[1:],\n",
    "                                               side_SB_count[1:]):\n",
    "        if sb_a_count==0 or sb_b_count==0:\n",
    "            is_parralel_with_next.append(False)\n",
    "            continue\n",
    "        if max_distance is None or max(sb_a,sb_b)<=max_distance:\n",
    "            is_parralel_with_next.append(abs(sb_a-sb_b)<PARAM_sight_line_spacing/3)\n",
    "        else:\n",
    "            is_parralel_with_next.append(False)\n",
    "    # choice for last point\n",
    "    is_parralel_with_next.append(False)\n",
    "\n",
    "\n",
    "    result=[]    \n",
    "    prev_parralel = False\n",
    "    for next_parralel,w,w_is_def in zip(is_parralel_with_next,\n",
    "                               side_SB,\n",
    "                               side_SB_count):\n",
    "        # Ajouter condition su \n",
    "        factor = 0\n",
    "        if prev_parralel:#max_distance\n",
    "            #STOP\n",
    "            factor+=0.5\n",
    "        if next_parralel:\n",
    "            factor+=0.5\n",
    "        result.append(factor)\n",
    "        prev_parralel=next_parralel\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8c21c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition si N>1            --> eb_rate(N-1)\n",
    "# definition si n_l>1          --> eb_rate(n_l-1)\n",
    "# definition si n_r>1          --> eb_rate(n_r-1)\n",
    "# definition si n_r>1 or n_l>1 --> eb_rate( (max(1,n_l)+max(1,n_r)-2) !!! \n",
    "\n",
    "def compute_parallelism_indicators(left_SB,\n",
    "                                   left_SB_count,\n",
    "                                   right_SB,\n",
    "                                   right_SB_count,\n",
    "                                   N,n_l,n_r,\n",
    "                                   max_distance=None):\n",
    "    parallel_left_factors = compute_parallelism_factor(left_SB,\n",
    "                                                       left_SB_count,\n",
    "                                                       max_distance)\n",
    "    parallel_right_factors = compute_parallelism_factor(right_SB,\n",
    "                                                        right_SB_count,\n",
    "                                                        max_distance)\n",
    "\n",
    "    \n",
    "    parallel_left_total = sum(parallel_left_factors)   \n",
    "    parallel_right_total = sum(parallel_right_factors)   \n",
    "\n",
    "    ind_left_par_tot = parallel_left_total/(N-1) if N>1 else math.nan\n",
    "    ind_left_par_rel = parallel_left_total/(n_l-1) if n_l > 1 else math.nan\n",
    "\n",
    "    ind_right_par_tot = parallel_right_total/(N-1) if N>1 else math.nan\n",
    "    ind_right_par_rel = parallel_right_total/(n_r-1) if n_r > 1 else math.nan\n",
    "\n",
    "\n",
    "    ind_par_tot=math.nan    \n",
    "    if N>1:\n",
    "        ind_par_tot=(parallel_left_total+parallel_right_total)/(2*N-2)\n",
    "\n",
    "    ind_par_rel=math.nan\n",
    "    if n_l>1 or n_r>1:\n",
    "        ind_par_rel=(parallel_left_total+parallel_right_total)/(max(1,n_l)+max(1,n_r)-2)\n",
    "    \n",
    "    return ind_left_par_tot,ind_left_par_rel,\\\n",
    "           ind_right_par_tot,ind_right_par_rel,\\\n",
    "           ind_par_tot,ind_par_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb6428c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_street_indicators(df_sightlines):\n",
    "    values=[]\n",
    "    nb_streets=len(df_sightlines)\n",
    "\n",
    "    #for street_uid, row in df_sightlines.loc[[74333382]].iterrows():\n",
    "    for street_uid, row in df_sightlines.iterrows():\n",
    "\n",
    "        street_length = row.street_length\n",
    "\n",
    "        left_OS_count = row.left_OS_count\n",
    "        left_OS = row.left_OS\n",
    "        left_SB_count = row.left_SB_count\n",
    "        left_SB = row.left_SB\n",
    "        left_H = row.left_H\n",
    "        left_HW = row.left_HW\n",
    "        right_OS_count = row.right_OS_count\n",
    "        right_OS = row.right_OS\n",
    "        right_SB_count = row.right_SB_count\n",
    "        right_SB = row.right_SB\n",
    "        right_H = row.right_H\n",
    "        right_HW = row.right_HW\n",
    "\n",
    "\n",
    "        left_BUILT_COVERAGE = row.left_BUILT_COVERAGE\n",
    "        left_SEQ_SB_categories = row.left_SEQ_SB_categories\n",
    "        left_SEQ_SB_ids = row.left_SEQ_SB_ids\n",
    "\n",
    "        right_BUILT_COVERAGE = row.right_BUILT_COVERAGE\n",
    "        right_SEQ_SB_categories = row.right_SEQ_SB_categories\n",
    "        right_SEQ_SB_ids = row.right_SEQ_SB_ids\n",
    "\n",
    "\n",
    "        front_SB = row.front_SB\n",
    "        back_SB = row.back_SB\n",
    "\n",
    "\n",
    "        N=len(left_OS_count)\n",
    "        if N==0:  \n",
    "            continue\n",
    "\n",
    "        # ------------------------\n",
    "        # OPENNESS     \n",
    "        # ------------------------\n",
    "        sum_left_OS = np.sum(left_OS)\n",
    "        sum_right_OS = np.sum(right_OS)\n",
    "\n",
    "        ind_left_OS = sum_left_OS/N\n",
    "        ind_right_OS = sum_right_OS/N\n",
    "        ind_OS = ind_left_OS+ind_right_OS # ==(left_OS+right_OS)/N\n",
    "\n",
    "\n",
    "        full_OS=[l+r for l,r in zip(left_OS,right_OS)]\n",
    "        # mediane >> med\n",
    "        ind_left_OS_med = np.median(left_OS)\n",
    "        ind_right_OS_med = np.median(right_OS)\n",
    "        ind_OS_med = np.median(full_OS) \n",
    "\n",
    "\n",
    "        # OPENNESS ROUGHNESS        \n",
    "        sum_square_error_left_OS= np.sum([(os-ind_left_OS)**2 for os in left_OS])\n",
    "        sum_square_error_right_OS= np.sum([(os-ind_right_OS)**2 for os in right_OS])\n",
    "        sum_abs_error_left_OS= np.sum([abs(os-ind_left_OS) for os in left_OS])\n",
    "        sum_abs_error_right_OS= np.sum([abs(os-ind_right_OS) for os in right_OS])    \n",
    "        ind_OS_STD =  math.sqrt((sum_square_error_left_OS+sum_square_error_right_OS)/(2*N-1))    \n",
    "        ind_OS_MAD =(sum_abs_error_left_OS+sum_abs_error_right_OS)/(2*N)\n",
    "\n",
    "        ind_left_OS_STD = 0 # default\n",
    "        ind_right_OS_STD = 0 # default\n",
    "        ind_left_OS_MAD = 0 # default\n",
    "        ind_right_OS_MAD = 0 # default\n",
    "\n",
    "        ind_left_OS_MAD =  sum_abs_error_left_OS/N\n",
    "        ind_right_OS_MAD = sum_abs_error_right_OS/N\n",
    "        if N > 1:\n",
    "            ind_left_OS_STD = math.sqrt((sum_square_error_left_OS)/(N-1))\n",
    "            ind_right_OS_STD = math.sqrt((sum_square_error_right_OS)/(N-1))\n",
    "\n",
    "\n",
    "        sum_abs_error_left_OS_med= np.sum([abs(os-ind_left_OS_med) for os in left_OS])\n",
    "        sum_abs_error_right_OS_med= np.sum([abs(os-ind_right_OS_med) for os in right_OS])    \n",
    "        ind_left_OS_MAD_med=sum_abs_error_left_OS_med/N\n",
    "        ind_right_OS_MAD_med=sum_abs_error_right_OS_med/N\n",
    "        ind_OS_MAD_med=(sum_abs_error_left_OS_med+sum_abs_error_right_OS_med)/(2*N)\n",
    "\n",
    "\n",
    "        # ------------------------     \n",
    "        # SETBACK\n",
    "        # ------------------------ \n",
    "        rel_left_SB = [x for x in left_SB if not math.isnan(x)]   \n",
    "        rel_right_SB = [x for x in right_SB if not math.isnan(x)]    \n",
    "        n_l = len(rel_left_SB)\n",
    "        n_r = len(rel_right_SB)\n",
    "        n_l_plus_r = n_l + n_r\n",
    "        sum_left_SB = np.sum(rel_left_SB)\n",
    "        sum_right_SB = np.sum(rel_right_SB)  \n",
    "\n",
    "\n",
    "        # SETBACK default values\n",
    "        ind_left_SB = sum_left_SB / n_l if n_l > 0 else PARAM_sight_line_width\n",
    "        ind_right_SB = sum_right_SB / n_r if n_r > 0 else PARAM_sight_line_width\n",
    "        ind_SB = (sum_left_SB + sum_right_SB) / (n_l_plus_r) if n_l_plus_r > 0 else PARAM_sight_line_width\n",
    "\n",
    "        sum_square_error_left_SB = np.sum([(x-ind_left_SB)**2 for x in rel_left_SB])\n",
    "        sum_square_error_right_SB = np.sum([(x-ind_right_SB)**2 for x in rel_right_SB])\n",
    "\n",
    "\n",
    "\n",
    "        ind_left_SB_STD = math.sqrt(sum_square_error_left_SB / (n_l - 1)) if n_l > 1 else 0    \n",
    "        ind_right_SB_STD = math.sqrt(sum_square_error_right_SB / (n_r - 1)) if n_r > 1 else 0\n",
    "        ind_SB_STD = math.sqrt((sum_square_error_left_SB+sum_square_error_right_SB)/(n_l_plus_r - 1)) if n_l_plus_r > 1 else 0\n",
    "\n",
    "\n",
    "        # medianes\n",
    "        ind_left_SB_med = np.median(rel_left_SB) if n_l > 0 else PARAM_sight_line_width\n",
    "        ind_right_SB_med =  np.median(rel_right_SB) if n_r > 0 else PARAM_sight_line_width\n",
    "        ind_SB_med = np.median(np.concatenate([rel_left_SB,rel_right_SB])) if n_l_plus_r > 0 else PARAM_sight_line_width\n",
    "\n",
    "        # MAD\n",
    "        sum_abs_error_left_SB = np.sum([abs(x-ind_left_SB) for x in rel_left_SB])\n",
    "        sum_abs_error_right_SB = np.sum([abs(x-ind_right_SB) for x in rel_right_SB])    \n",
    "        ind_left_SB_MAD = sum_abs_error_left_SB / n_l if n_l > 0 else 0\n",
    "        ind_right_SB_MAD = sum_abs_error_right_SB / n_r if n_r > 0 else 0\n",
    "        ind_SB_MAD = (sum_abs_error_left_SB+sum_abs_error_right_SB)/(n_l_plus_r) if n_l_plus_r > 0 else 0\n",
    "\n",
    "        # MAD_med\n",
    "        sum_abs_error_left_SB_med = np.sum([abs(x-ind_left_SB_med) for x in rel_left_SB])\n",
    "        sum_abs_error_right_SB_med = np.sum([abs(x-ind_right_SB_med) for x in rel_right_SB])    \n",
    "        ind_left_SB_MAD_med = sum_abs_error_left_SB_med / n_l if n_l > 0 else 0\n",
    "        ind_right_SB_MAD_med = sum_abs_error_right_SB_med / n_r if n_r > 0 else 0\n",
    "        ind_SB_MAD_med = (sum_abs_error_left_SB_med+sum_abs_error_right_SB_med)/(n_l_plus_r) if n_l_plus_r > 0 else 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # ------------------------     \n",
    "        # HEIGHT\n",
    "        # ------------------------ \n",
    "        rel_left_H = [x for x in left_H if not math.isnan(x)]   \n",
    "        rel_right_H = [x for x in right_H if not math.isnan(x)]    \n",
    "        sum_left_H = np.sum(rel_left_H)\n",
    "        sum_right_H = np.sum(rel_right_H)  \n",
    "\n",
    "\n",
    "        # HEIGHT AVERAGE default values\n",
    "        ind_left_H = sum_left_H / n_l if n_l > 0 else 0\n",
    "        ind_right_H = sum_right_H / n_r if n_r > 0 else 0\n",
    "        ind_H = (sum_left_H + sum_right_H) / (n_l_plus_r) if n_l_plus_r > 0 else 0\n",
    "\n",
    "        sum_square_error_left_H = np.sum([(x-ind_left_H)**2 for x in rel_left_H])\n",
    "        sum_square_error_right_H = np.sum([(x-ind_right_H)**2 for x in rel_right_H])\n",
    "\n",
    "        ind_left_H_STD = math.sqrt(sum_square_error_left_H / (n_l - 1)) if n_l > 1 else 0\n",
    "        ind_right_H_STD = math.sqrt(sum_square_error_right_H / (n_r - 1)) if n_r > 1 else 0\n",
    "        ind_H_STD = math.sqrt((sum_square_error_left_H+sum_square_error_right_H)/(n_l_plus_r - 1)) if n_l_plus_r > 1 else 0\n",
    "\n",
    "        # ------------------------     \n",
    "        # CROSS_SECTION_PROPORTION (cross sectionnal ratio)\n",
    "        # ------------------------ \n",
    "        rel_left_HW = [x for x in left_HW if not math.isnan(x)]   \n",
    "        rel_right_HW = [x for x in right_HW if not math.isnan(x)]    \n",
    "        sum_left_HW = np.sum(rel_left_HW)\n",
    "        sum_right_HW = np.sum(rel_right_HW)  \n",
    "\n",
    "\n",
    "        ind_left_HW = sum_left_HW / n_l if n_l > 0 else 0\n",
    "        ind_right_HW = sum_right_HW / n_r if n_r > 0 else 0\n",
    "        ind_HW = (sum_left_HW + sum_right_HW) / (n_l_plus_r) if n_l_plus_r > 0 else 0\n",
    "\n",
    "        sum_square_error_left_HW = np.sum([(x-ind_left_HW)**2 for x in rel_left_HW])\n",
    "        sum_square_error_right_HW = np.sum([(x-ind_right_HW)**2 for x in rel_right_HW])\n",
    "\n",
    "        ind_left_HW_STD = math.sqrt(sum_square_error_left_HW / (n_l - 1)) if n_l > 1 else 0\n",
    "        ind_right_HW_STD = math.sqrt(sum_square_error_right_HW / (n_r - 1)) if n_r > 1 else 0\n",
    "        ind_HW_STD = math.sqrt((sum_square_error_left_HW+sum_square_error_right_HW)/(n_l_plus_r - 1)) if n_l_plus_r > 1 else 0\n",
    "\n",
    "        # --------------------------------     \n",
    "        # CROSS_SECTIONNAL OPEN VIEW ANGLE\n",
    "        # --------------------------------\n",
    "        left_angles = [np.rad2deg(np.arctan(hw)) if not math.isnan(hw) else 0 for hw in left_HW]\n",
    "        right_angles = [np.rad2deg(np.arctan(hw)) if not math.isnan(hw) else 0 for hw in right_HW]\n",
    "\n",
    "        angles = [180-gamma_l-gamma_r for gamma_l,gamma_r in zip(left_angles,right_angles)]\n",
    "        ind_csosva = sum(angles)/N\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # ------------------------\n",
    "        # TANGENTE Ratio (front+back/OS if setback exists)\n",
    "        # ------------------------\n",
    "        all_tan=[]\n",
    "        all_tan_ratio=[]    \n",
    "        for f,b,l,r in zip(front_SB,back_SB,left_OS,right_OS):        \n",
    "            tan_value = f+b\n",
    "            all_tan.append(tan_value)\n",
    "            if not math.isnan(l) and not  math.isnan(r):   \n",
    "                all_tan_ratio.append(tan_value/(l+r))    \n",
    "\n",
    "        # Tan\n",
    "        ind_tan = np.sum(all_tan)/N\n",
    "        ind_tan_STD = 0\n",
    "        if N > 1:\n",
    "            ind_tan_STD = math.sqrt(np.sum([(x-ind_tan)**2 for x in all_tan]) / (N-1))        \n",
    "\n",
    "        # Tan ratio\n",
    "        ind_tan_ratio = 0 \n",
    "        ind_tan_ratio_STD = 0 \n",
    "        n_tan_ratio = len(all_tan_ratio)\n",
    "        if n_tan_ratio>0:\n",
    "            ind_tan_ratio = np.sum(all_tan_ratio)/n_tan_ratio\n",
    "            if n_tan_ratio > 1:\n",
    "                ind_tan_ratio_STD = math.sqrt(np.sum([(x-ind_tan_ratio)**2 for x in all_tan_ratio]) / (n_tan_ratio-1))        \n",
    "\n",
    "\n",
    "        # version de l'indictaur sans horizon (max = sightline_width)\n",
    "        ind_left_par_tot,ind_left_par_rel,\\\n",
    "        ind_right_par_tot,ind_right_par_rel,\\\n",
    "        ind_par_tot,ind_par_rel = compute_parallelism_indicators(left_SB,left_SB_count,\n",
    "                                                             right_SB,right_SB_count,\n",
    "                                                             N,n_l,n_r,\n",
    "                                                             max_distance=None)\n",
    "\n",
    "        # version de l'indictaur a 15 m√®tres maximum\n",
    "        ind_left_par_tot_15,ind_left_par_rel_15,\\\n",
    "        ind_right_par_tot_15,ind_right_par_rel_15,\\\n",
    "        ind_par_tot_15,ind_par_rel_15 = compute_parallelism_indicators(left_SB,left_SB_count,\n",
    "                                                             right_SB,right_SB_count,\n",
    "                                                             N,n_l,n_r,\n",
    "                                                             max_distance=15)\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\" OLD PARRLELISM\n",
    "        NOUVEAU PAR √† 15\n",
    "        parallel_left_factors = compute_parallelism_factor(left_SB,left_SB_count,15)\n",
    "        # PARALLELISM INDICATORS\n",
    "        parallel_left_factors = compute_parallelism_factor(left_SB,left_SB_count)\n",
    "        parallel_right_factors = compute_parallelism_factor(right_SB,right_SB_count)\n",
    "        parallel_left_total = sum(parallel_left_factors)\n",
    "        parallel_right_total = sum(parallel_right_factors)\n",
    "        parallel_all_total = parallel_right_total+parallel_left_total\n",
    "\n",
    "        ind_par_tot = parallel_all_total/(2*N)\n",
    "        ind_par_rel = parallel_all_total/(n_l_plus_r)  if n_l_plus_r > 0 else 0\n",
    "        # ?Nouvel indicateur\n",
    "        ind_par_rel_15\n",
    "\n",
    "        ind_left_par_tot = parallel_left_total/N\n",
    "        ind_right_par_tot = parallel_right_total/N\n",
    "        ind_left_par_rel = parallel_left_total/n_l if n_l > 0 else 0\n",
    "        ind_right_par_rel = parallel_right_total/n_r if n_r > 0 else 0\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "        # Built frequency\n",
    "        ind_left_built_freq = len(set(left_SEQ_SB_ids))/street_length\n",
    "        ind_right_built_freq = len(set(right_SEQ_SB_ids))/street_length\n",
    "        ind_built_freq = len(set(left_SEQ_SB_ids+right_SEQ_SB_ids))/street_length\n",
    "\n",
    "        # Built coverage\n",
    "        ind_left_built_coverage = np.mean(left_BUILT_COVERAGE)/PARAM_sight_line_width\n",
    "        ind_right_built_coverage = np.mean(right_BUILT_COVERAGE)/PARAM_sight_line_width\n",
    "        ind_built_coverage = (ind_left_built_coverage+ind_right_built_coverage)/2\n",
    "\n",
    "\n",
    "\n",
    "        # Built category prevvvalence\n",
    "\n",
    "\n",
    "        values.append([street_uid,\n",
    "                       N,n_l,n_r,\n",
    "                      ind_left_OS,ind_right_OS, ind_OS,\n",
    "                      ind_left_OS_STD,ind_right_OS_STD, ind_OS_STD,\n",
    "                      ind_left_OS_MAD,ind_right_OS_MAD, ind_OS_MAD,\n",
    "                      ind_left_OS_med,ind_right_OS_med, ind_OS_med,\n",
    "                      ind_left_OS_MAD_med, ind_right_OS_MAD_med, ind_OS_MAD_med,\n",
    "                      ind_left_SB, ind_right_SB, ind_SB,\n",
    "                      ind_left_SB_STD, ind_right_SB_STD, ind_SB_STD,\n",
    "                      ind_left_SB_MAD,ind_right_SB_MAD, ind_SB_MAD,\n",
    "                      ind_left_SB_med,ind_right_SB_med, ind_SB_med,\n",
    "                      ind_left_SB_MAD_med, ind_right_SB_MAD_med, ind_SB_MAD_med,\n",
    "                      ind_left_H, ind_right_H, ind_H,\n",
    "                      ind_left_H_STD, ind_right_H_STD, ind_H_STD,\n",
    "                      ind_left_HW, ind_right_HW, ind_HW,\n",
    "                      ind_left_HW_STD, ind_right_HW_STD, ind_HW_STD,\n",
    "                      ind_csosva,\n",
    "                      ind_tan,\n",
    "                      ind_tan_STD,\n",
    "                      n_tan_ratio,\n",
    "                      ind_tan_ratio,\n",
    "                      ind_tan_ratio_STD,\n",
    "                      ind_par_tot,ind_par_rel,                   \n",
    "                      ind_left_par_tot,ind_right_par_tot,\n",
    "                      ind_left_par_rel,ind_right_par_rel,\n",
    "                      ind_par_tot_15,ind_par_rel_15,  \n",
    "                      ind_left_par_tot_15,ind_right_par_tot_15,\n",
    "                      ind_left_par_rel_15,ind_right_par_rel_15,\n",
    "                      ind_left_built_freq, ind_right_built_freq, ind_built_freq,\n",
    "                      ind_left_built_coverage, ind_right_built_coverage, ind_built_coverage\n",
    "                      ])\n",
    "\n",
    "    df = pd.DataFrame(values,columns=['uid',\n",
    "                                      'N','n_l','n_r',\n",
    "                                      'left_OS','right_OS', 'OS',\n",
    "                                      'left_OS_STD','right_OS_STD', 'OS_STD',\n",
    "                                      'left_OS_MAD','right_OS_MAD', 'OS_MAD',\n",
    "                                      'left_OS_med','right_OS_med', 'OS_med',\n",
    "                                      'left_OS_MAD_med','right_OS_MAD_med', 'OS_MAD_med',\n",
    "                                      'left_SB','right_SB', 'SB',\n",
    "                                      'left_SB_STD','right_SB_STD', 'SB_STD',\n",
    "                                      'left_SB_MAD','right_SB_MAD', 'SB_MAD',\n",
    "                                      'left_SB_med','right_SB_med', 'SB_med',\n",
    "                                      'left_SB_MAD_med','right_SB_MAD_med', 'SB_MAD_med',\n",
    "                                      'left_H','right_H', 'H',\n",
    "                                      'left_H_STD','right_H_STD', 'H_STD',\n",
    "                                      'left_HW','right_HW', 'HW',\n",
    "                                      'left_HW_STD','right_HW_STD', 'HW_STD',\n",
    "                                      'csosva',\n",
    "                                      'tan',\n",
    "                                      'tan_STD',\n",
    "                                      'n_tan_ratio',\n",
    "                                      'tan_ratio',\n",
    "                                      'tan_ratio_STD',\n",
    "                                      'par_tot','par_rel',\n",
    "                                      'left_par_tot','right_par_tot',\n",
    "                                      'left_par_rel','right_par_rel',\n",
    "                                      'par_tot_15','par_rel_15',\n",
    "                                      'left_par_tot_15','right_par_tot_15',\n",
    "                                      'left_par_rel_15','right_par_rel_15',\n",
    "                                      'left_built_freq', 'right_built_freq', 'built_freq',\n",
    "                                      'left_built_coverage', 'right_built_coverage', 'built_coverage']).set_index('uid')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f064fa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_building_category_prevalence_indicators(SB_count, SEQ_SB_categories):    \n",
    "    \n",
    "    sb_sequence_id = 0\n",
    "    category_total_weight = 0    \n",
    "    category_counters = np.zeros(PARAM_building_categories_count)\n",
    "    for sb_count in SB_count:\n",
    "        if sb_count==0:\n",
    "            continue        \n",
    "        # add sight line contribution relative to snail effect\n",
    "        sb_weight = 1/sb_count\n",
    "        category_total_weight += 1        \n",
    "        for i in range(sb_count):\n",
    "            category_counters[SEQ_SB_categories[sb_sequence_id]]+=sb_weight\n",
    "            sb_sequence_id+=1            \n",
    "            \n",
    "    return category_counters, category_total_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cfa8a0c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def compute_prevalences(df_sighlines):\n",
    "    values=[]\n",
    "\n",
    "    for street_uid, row in df_sightlines.iterrows():\n",
    "\n",
    "        left_SEQ_SB_categories=row.left_SEQ_SB_categories\n",
    "        left_SB_count=row.left_SB_count\n",
    "        right_SEQ_SB_categories=row.right_SEQ_SB_categories\n",
    "        right_SB_count=row.right_SB_count\n",
    "\n",
    "        # left right totalizer    \n",
    "        left_category_indicators, left_category_total_weight = compute_building_category_prevalence_indicators(left_SB_count,left_SEQ_SB_categories)\n",
    "        right_category_indicators, right_category_total_weight = compute_building_category_prevalence_indicators(right_SB_count,right_SEQ_SB_categories)\n",
    "\n",
    "        # global  totalizer    \n",
    "        category_indicators = left_category_indicators+right_category_indicators # numpy #add X+Y = Z wxhere zi=xi+yi \n",
    "        category_total_weight = left_category_total_weight+right_category_total_weight\n",
    "\n",
    "\n",
    "        left_category_indicators = left_category_indicators/left_category_total_weight if left_category_total_weight!=0 else left_category_indicators\n",
    "        right_category_indicators = right_category_indicators/right_category_total_weight if right_category_total_weight!=0 else right_category_indicators\n",
    "        category_indicators =  category_indicators/category_total_weight if category_total_weight!=0 else category_indicators\n",
    "\n",
    "        values.append([street_uid]+list(category_indicators)) \n",
    "\n",
    "    columns= ['uid']+[f'building_prevalence_T{clazz}' for clazz in range(PARAM_building_categories_count)]\n",
    "    df_prevalences = pd.DataFrame(values,columns=columns).set_index('uid')\n",
    "\n",
    "    display(f'{len(df_prevalences)} rows (prevalence)')\n",
    "    return df_prevalences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d233d1f2",
   "metadata": {},
   "source": [
    "# Main Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3d6ca59",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_sightlines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_indicators\u001b[38;5;241m=\u001b[39mcompute_street_indicators(\u001b[43mdf_sightlines\u001b[49m)\n\u001b[1;32m      2\u001b[0m df_prevalences\u001b[38;5;241m=\u001b[39mcompute_prevalences(df_sightlines)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Primary global indictaors\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_sightlines' is not defined"
     ]
    }
   ],
   "source": [
    "df_indicators=compute_street_indicators(df_sightlines)\n",
    "df_prevalences=compute_prevalences(df_sightlines)\n",
    "\n",
    "# Primary global indictaors\n",
    "df_results = df_sightlines[['nodes_degree_1',\n",
    "                            'nodes_degree_4',\n",
    "                            'nodes_degree_3_5_plus',\n",
    "                            'street_length',\n",
    "                            'windingness']].copy()\n",
    "# Join with all sightlines indicators\n",
    "df_results = df_results.join(df_indicators)\n",
    "# Join with prevalences  indicators\n",
    "df_results = df_results.join(df_prevalences)\n",
    "# consolidate fields N n_l and n_l when missing (set to zero)\n",
    "df_results['N'] = df_results['N'].fillna(0)\n",
    "\n",
    "print(f'{len(df_sightlines)} rows for sightlines metrics')\n",
    "print(f'{len(df_prevalences)} rows for road prevalences')\n",
    "print(f'{len(df_results)} rows in road results')    \n",
    "del df_sightlines\n",
    "del df_prevalences\n",
    "gc.collect()\n",
    "\n",
    "# fs_cache.save_to_pickle(df_results,output_theme,output_name,\n",
    "#                     verbose=display)\n",
    "# print(f'Export zone indicators {zone_code} as CSV')\n",
    "# fs_cache.dataframe_to_csv(df_results[df_results.N!=0],\n",
    "#                       'road_indicators',f'{PARAM_insee_layer_name}_{zone_code}_road_indicators')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
